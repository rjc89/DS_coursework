{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module4- Lab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look pretty...\n",
    "\n",
    "# matplotlib.style.use('ggplot')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Boilerplate Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For your convenience, we've included some boilerplate code here which will help you out. You aren't expected to know how to write this code on your own at this point, but it'll assist with your visualizations. We've added some notes to the code in case you're interested in knowing what it's doing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A Note on SKLearn's `.transform()` calls:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time you perform a transformation on your data, you lose the column header names because the output of SciKit-Learn's `.transform()` method is an NDArray and not a daraframe.\n",
    "\n",
    "This actually makes a lot of sense because there are essentially two types of transformations:\n",
    "- Those that adjust the scale of your features, and\n",
    "- Those that change alter the number of features, perhaps even changing their values entirely.\n",
    "\n",
    "An example of adjusting the scale of a feature would be changing centimeters to inches. Changing the feature entirely would be like using PCA to reduce 300 columns to 30. In either case, the original column's units have either been altered or no longer exist at all, so it's up to you to assign names to your columns after any transformation, if you'd like to store the resulting NDArray back into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaleFeaturesDF(df):\n",
    "    # Feature scaling is a type of transformation that only changes the\n",
    "    # scale, but not number of features. Because of this, we can still\n",
    "    # use the original dataset's column names... so long as we keep in\n",
    "    # mind that the _units_ have been altered:\n",
    "\n",
    "    scaled = preprocessing.StandardScaler().fit_transform(df)\n",
    "    scaled = pd.DataFrame(scaled, columns=df.columns)\n",
    "    \n",
    "    print(\"New Variances:\\n\", scaled.var())\n",
    "    print(\"New Describe:\\n\", scaled.describe())\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SKLearn contains many methods for transforming your features by scaling them, a type of pre-processing):\n",
    "    - `RobustScaler`\n",
    "    - `Normalizer`\n",
    "    - `MinMaxScaler`\n",
    "    - `MaxAbsScaler`\n",
    "    - `StandardScaler`\n",
    "    - ...\n",
    "\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "\n",
    "However in order to be effective at PCA, there are a few requirements that must be met, and which will drive the selection of your scaler. PCA requires your data is standardized -- in other words, it's _mean_ should equal 0, and it should have unit variance.\n",
    "\n",
    "SKLearn's regular `Normalizer()` doesn't zero out the mean of your data, it only clamps it, so it could be inappropriate to use depending on your data. `MinMaxScaler` and `MaxAbsScaler` both fail to set a unit variance, so you won't be using them here either. `RobustScaler` can work, again depending on your data (watch for outliers!). So for this assignment, you're going to use the `StandardScaler`. Get familiar with it by visiting these two websites:\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, some code to help with visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawVectors(transformed_features, components_, columns, plt, scaled):\n",
    "    if not scaled:\n",
    "        return plt.axes() # No cheating ;-)\n",
    "\n",
    "    num_columns = len(columns)\n",
    "\n",
    "    # This funtion will project your *original* feature (columns)\n",
    "    # onto your principal component feature-space, so that you can\n",
    "    # visualize how \"important\" each one was in the\n",
    "    # multi-dimensional scaling\n",
    "\n",
    "    # Scale the principal components by the max value in\n",
    "    # the transformed set belonging to that component\n",
    "    xvector = components_[0] * max(transformed_features[:,0])\n",
    "    yvector = components_[1] * max(transformed_features[:,1])\n",
    "\n",
    "    ## visualize projections\n",
    "\n",
    "    # Sort each column by it's length. These are your *original*\n",
    "    # columns, not the principal components.\n",
    "    important_features = { columns[i] : math.sqrt(xvector[i]**2 + yvector[i]**2) for i in range(num_columns) }\n",
    "    important_features = sorted(zip(important_features.values(), important_features.keys()), reverse=True)\n",
    "    print(\"Features by importance:\\n\", important_features)\n",
    "\n",
    "    ax = plt.axes()\n",
    "\n",
    "    for i in range(num_columns):\n",
    "        # Use an arrow to project each original feature as a\n",
    "        # labeled vector on your principal component axes\n",
    "        plt.arrow(0, 0, xvector[i], yvector[i], color='b', width=0.0005, head_width=0.02, alpha=0.75)\n",
    "        plt.text(xvector[i]*1.2, yvector[i]*1.2, list(columns)[i], color='b', alpha=0.75)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And Now, The Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do * NOT * alter this line, until instructed!\n",
    "scaleFeatures = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the dataset specified on the lab instructions page and remove any and all _rows_ that have a NaN in them. You should be a pro at this by now ;-)\n",
    "\n",
    "**QUESTION**: Should the `id` column be included in your dataset as a feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "       ...        pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
       "0      ...         44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
       "1      ...         38  6000  NaN   no   no   no  good   no   no            ckd  \n",
       "2      ...         31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
       "3      ...         32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
       "4      ...         35  7300  4.6   no   no   no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "df = pd.read_csv('/Users/constar/Documents/GitHub/Online_courses/DAT210x-master/Module4/Datasets/kidney_disease.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.to_csv('/Users/constar/Desktop/module4lab2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  int64\n",
       "age               float64\n",
       "bp                float64\n",
       "sg                float64\n",
       "al                float64\n",
       "su                float64\n",
       "rbc                object\n",
       "pc                 object\n",
       "pcc                object\n",
       "ba                 object\n",
       "bgr               float64\n",
       "bu                float64\n",
       "sc                float64\n",
       "sod               float64\n",
       "pot               float64\n",
       "hemo              float64\n",
       "pcv                object\n",
       "wc                 object\n",
       "rc                 object\n",
       "htn                object\n",
       "dm                 object\n",
       "cad                object\n",
       "appet              object\n",
       "pe                 object\n",
       "ane                object\n",
       "classification     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build some color-coded labels; the actual label feature will be removed prior to executing PCA, since it's unsupervised. You're only labeling by color so you can see the effects of PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['red' if i=='ckd' else 'green' for i in df.classification]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use an indexer to select only the following columns: `['bgr','wc','rc']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your code here ..\n",
    "\n",
    "selection = df.loc(['bgr','wc','rc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either take a look at the dataset's webpage in the attribute info section of UCI's [Chronic Kidney Disease]() page,: https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease or alternatively, you can actually look at the first few rows of your dataframe using `.head()`. What kind of data type should these three columns be? Compare what you see with the results when you print out your dataframe's `dtypes`.\n",
    "\n",
    "If Pandas did not properly detect and convert your columns to the data types you expected, use an appropriate command to coerce these features to the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arg must be a list, tuple, 1-d array, or Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-cd39ad103aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#df[numeric] = df[numeric].apply(pd.to_numeric, errors='coerce')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arg must be a list, tuple, 1-d array, or Series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: arg must be a list, tuple, 1-d array, or Series"
     ]
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "#import numpy as np\n",
    "#df['pcv' ] = df['pcv'].astype(np.float64)\n",
    "\n",
    "\n",
    "\n",
    "#cols = df.columns.drop('id')\n",
    "\n",
    "#df[cols] = df[cols].apply(pd.to_numeric, errors='coerce'\n",
    "\n",
    "#to_numeric\n",
    "\n",
    "\n",
    "####numeric = ['pcv','wc','rc']\n",
    "\n",
    "####df[numeric] = df[numeric].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "#numeric = ['lots', 'a', 'columns']\n",
    "\n",
    "\n",
    "#df[numeric] = df[numeric].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df = pd.to_numeric(df, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  int64\n",
       "age               float64\n",
       "bp                float64\n",
       "sg                float64\n",
       "al                float64\n",
       "su                float64\n",
       "rbc                object\n",
       "pc                 object\n",
       "pcc                object\n",
       "ba                 object\n",
       "bgr               float64\n",
       "bu                float64\n",
       "sc                float64\n",
       "sod               float64\n",
       "pot               float64\n",
       "hemo              float64\n",
       "pcv               float64\n",
       "wc                  int64\n",
       "rc                float64\n",
       "htn                object\n",
       "dm                 object\n",
       "cad                object\n",
       "appet              object\n",
       "pe                 object\n",
       "ane                object\n",
       "classification     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Operates based on variance. The variable with the greatest variance will dominate. Examine your data using a command that will check the variance of every feature in your dataset, and then print out the results. Also print out the results of running `.describe` on your dataset.\n",
    "\n",
    "_Hint:_ If you do not see all three variables: `'bgr'`, `'wc'`, and `'rc'`, then it's likely you probably did not complete the previous step properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       id   age     bp     sg   al   su       rbc        pc         pcc  \\\n",
       "3      3  48.0   70.0  1.005  4.0  0.0    normal  abnormal     present   \n",
       "9      9  53.0   90.0  1.020  2.0  0.0  abnormal  abnormal     present   \n",
       "11    11  63.0   70.0  1.010  3.0  0.0  abnormal  abnormal     present   \n",
       "14    14  68.0   80.0  1.010  3.0  2.0    normal  abnormal     present   \n",
       "20    20  61.0   80.0  1.015  2.0  0.0  abnormal  abnormal  notpresent   \n",
       "22    22  48.0   80.0  1.025  4.0  0.0    normal  abnormal  notpresent   \n",
       "27    27  69.0   70.0  1.010  3.0  4.0    normal  abnormal  notpresent   \n",
       "48    48  73.0   70.0  1.005  0.0  0.0    normal    normal  notpresent   \n",
       "58    58  73.0   80.0  1.020  2.0  0.0  abnormal  abnormal  notpresent   \n",
       "71    71  46.0   60.0  1.010  1.0  0.0    normal    normal  notpresent   \n",
       "74    74  56.0   90.0  1.015  2.0  0.0  abnormal  abnormal  notpresent   \n",
       "76    76  48.0   80.0  1.005  4.0  0.0  abnormal  abnormal  notpresent   \n",
       "84    84  59.0   70.0  1.010  3.0  0.0    normal  abnormal  notpresent   \n",
       "90    90  63.0  100.0  1.010  2.0  2.0    normal    normal  notpresent   \n",
       "91    91  56.0   70.0  1.015  4.0  1.0  abnormal    normal  notpresent   \n",
       "92    92  71.0   70.0  1.010  3.0  0.0    normal  abnormal     present   \n",
       "93    93  73.0  100.0  1.010  3.0  2.0  abnormal  abnormal     present   \n",
       "127  127  71.0   60.0  1.015  4.0  0.0    normal    normal  notpresent   \n",
       "128  128  52.0   90.0  1.015  4.0  3.0    normal  abnormal  notpresent   \n",
       "130  130  50.0   90.0  1.010  2.0  0.0    normal  abnormal     present   \n",
       "133  133  70.0  100.0  1.015  4.0  0.0    normal    normal  notpresent   \n",
       "144  144  60.0   90.0  1.010  2.0  0.0  abnormal    normal  notpresent   \n",
       "147  147  60.0   60.0  1.010  3.0  1.0    normal  abnormal     present   \n",
       "153  153  55.0   90.0  1.010  2.0  1.0  abnormal  abnormal  notpresent   \n",
       "157  157  62.0   70.0  1.025  3.0  0.0    normal  abnormal  notpresent   \n",
       "159  159  59.0   80.0  1.010  1.0  0.0  abnormal    normal  notpresent   \n",
       "171  171  83.0   70.0  1.020  3.0  0.0    normal    normal  notpresent   \n",
       "176  176  21.0   90.0  1.010  4.0  0.0    normal  abnormal     present   \n",
       "181  181  45.0   70.0  1.025  2.0  0.0    normal  abnormal     present   \n",
       "189  189  64.0   60.0  1.010  4.0  1.0  abnormal  abnormal  notpresent   \n",
       "..   ...   ...    ...    ...  ...  ...       ...       ...         ...   \n",
       "368  368  30.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "369  369  75.0   70.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "370  370  69.0   70.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "371  371  28.0   60.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "372  372  72.0   60.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "373  373  61.0   70.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "374  374  79.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "375  375  70.0   80.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "376  376  58.0   70.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "377  377  64.0   70.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "379  379  62.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "380  380  59.0   60.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "382  382  48.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "383  383  80.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "384  384  57.0   60.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "385  385  63.0   70.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "386  386  46.0   70.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "387  387  15.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "388  388  51.0   80.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "389  389  41.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "390  390  52.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "391  391  36.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "392  392  57.0   80.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "393  393  43.0   60.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "394  394  50.0   80.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "395  395  55.0   80.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "396  396  42.0   70.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "397  397  12.0   80.0  1.020  0.0  0.0    normal    normal  notpresent   \n",
       "398  398  17.0   60.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "399  399  58.0   80.0  1.025  0.0  0.0    normal    normal  notpresent   \n",
       "\n",
       "             ba      ...         pcv     wc   rc  htn   dm  cad  appet   pe  \\\n",
       "3    notpresent      ...        32.0   6700  3.9  yes   no   no   poor  yes   \n",
       "9    notpresent      ...        29.0  12100  3.7  yes  yes   no   poor   no   \n",
       "11   notpresent      ...        32.0   4500  3.8  yes  yes   no   poor  yes   \n",
       "14      present      ...        16.0  11000  2.6  yes  yes  yes   poor  yes   \n",
       "20   notpresent      ...        24.0   9200  3.2  yes  yes  yes   poor  yes   \n",
       "22   notpresent      ...        32.0   6900  3.4  yes   no   no   good   no   \n",
       "27   notpresent      ...        37.0   9600  4.1  yes  yes  yes   good  yes   \n",
       "48   notpresent      ...        29.0  18900  3.5  yes  yes   no   good  yes   \n",
       "58   notpresent      ...        33.0   7200  4.3  yes  yes  yes   good   no   \n",
       "71   notpresent      ...        28.0  14600  3.2  yes  yes   no   good   no   \n",
       "74   notpresent      ...        29.0   6400  3.4  yes   no   no   good   no   \n",
       "76      present      ...        36.0   6200  4.0   no  yes   no   good  yes   \n",
       "84   notpresent      ...        22.0   3800  2.1  yes   no   no   poor  yes   \n",
       "90      present      ...        40.0   9800  4.2  yes   no  yes   good   no   \n",
       "91   notpresent      ...        52.0  12500  5.6   no   no   no   good   no   \n",
       "92      present      ...        33.0   5600  3.6  yes  yes  yes   good   no   \n",
       "93   notpresent      ...        30.0   7000  3.2  yes  yes  yes   poor   no   \n",
       "127  notpresent      ...        35.0  15200  4.3  yes  yes   no   poor  yes   \n",
       "128  notpresent      ...        23.0   5000  2.9  yes  yes   no   good   no   \n",
       "130     present      ...        22.0  16300  2.7   no   no   no   poor  yes   \n",
       "133  notpresent      ...        37.0   8400  8.0  yes   no   no   good   no   \n",
       "144  notpresent      ...        33.0  10500  4.1   no   no   no   good   no   \n",
       "147  notpresent      ...        25.0  15200  3.0  yes   no   no   poor   no   \n",
       "153  notpresent      ...        22.0  14600  2.9  yes  yes   no   poor  yes   \n",
       "157  notpresent      ...        39.0   7900  3.9  yes  yes   no   good   no   \n",
       "159  notpresent      ...        35.0  10900  4.3   no  yes   no   poor   no   \n",
       "171  notpresent      ...        26.0  12800  3.1  yes   no   no   poor   no   \n",
       "176     present      ...        23.0  12400  3.9   no   no   no   good   no   \n",
       "181  notpresent      ...        30.0  19100  3.7   no   no   no   good   no   \n",
       "189     present      ...        29.0   7500  3.4  yes  yes   no   poor  yes   \n",
       "..          ...      ...         ...    ...  ...  ...  ...  ...    ...  ...   \n",
       "368  notpresent      ...        45.0   9400  5.9   no   no   no   good   no   \n",
       "369  notpresent      ...        46.0  10300  4.8   no   no   no   good   no   \n",
       "370  notpresent      ...        50.0   9300  5.4   no   no   no   good   no   \n",
       "371  notpresent      ...        51.0   6500  5.0   no   no   no   good   no   \n",
       "372  notpresent      ...        52.0  10500  5.5   no   no   no   good   no   \n",
       "373  notpresent      ...        47.0   9200  4.9   no   no   no   good   no   \n",
       "374  notpresent      ...        40.0   8000  6.4   no   no   no   good   no   \n",
       "375  notpresent      ...        48.0   9700  5.6   no   no   no   good   no   \n",
       "376  notpresent      ...        53.0   9100  5.2   no   no   no   good   no   \n",
       "377  notpresent      ...        49.0   6400  4.8   no   no   no   good   no   \n",
       "379  notpresent      ...        50.0   5400  5.7   no   no   no   good   no   \n",
       "380  notpresent      ...        54.0   6500  4.9   no   no   no   good   no   \n",
       "382  notpresent      ...        51.0   6000  6.5   no   no   no   good   no   \n",
       "383  notpresent      ...        49.0   5100  5.0   no   no   no   good   no   \n",
       "384  notpresent      ...        42.0  11000  4.5   no   no   no   good   no   \n",
       "385  notpresent      ...        52.0   8000  5.1   no   no   no   good   no   \n",
       "386  notpresent      ...        43.0   5700  6.5   no   no   no   good   no   \n",
       "387  notpresent      ...        50.0   6200  5.2   no   no   no   good   no   \n",
       "388  notpresent      ...        46.0   9500  6.4   no   no   no   good   no   \n",
       "389  notpresent      ...        52.0   7200  5.8   no   no   no   good   no   \n",
       "390  notpresent      ...        52.0   6300  5.3   no   no   no   good   no   \n",
       "391  notpresent      ...        44.0   5800  6.3   no   no   no   good   no   \n",
       "392  notpresent      ...        46.0   6600  5.5   no   no   no   good   no   \n",
       "393  notpresent      ...        54.0   7400  5.4   no   no   no   good   no   \n",
       "394  notpresent      ...        45.0   9500  4.6   no   no   no   good   no   \n",
       "395  notpresent      ...        47.0   6700  4.9   no   no   no   good   no   \n",
       "396  notpresent      ...        54.0   7800  6.2   no   no   no   good   no   \n",
       "397  notpresent      ...        49.0   6600  5.4   no   no   no   good   no   \n",
       "398  notpresent      ...        51.0   7200  5.9   no   no   no   good   no   \n",
       "399  notpresent      ...        53.0   6800  6.1   no   no   no   good   no   \n",
       "\n",
       "     ane classification  \n",
       "3    yes            ckd  \n",
       "9    yes            ckd  \n",
       "11    no            ckd  \n",
       "14    no            ckd  \n",
       "20   yes            ckd  \n",
       "22   yes            ckd  \n",
       "27    no            ckd  \n",
       "48    no            ckd  \n",
       "58    no            ckd  \n",
       "71    no            ckd  \n",
       "74    no            ckd  \n",
       "76    no            ckd  \n",
       "84   yes            ckd  \n",
       "90    no            ckd  \n",
       "91    no            ckd  \n",
       "92    no            ckd  \n",
       "93    no            ckd  \n",
       "127   no            ckd  \n",
       "128  yes            ckd  \n",
       "130  yes            ckd  \n",
       "133   no            ckd  \n",
       "144   no            ckd  \n",
       "147  yes            ckd  \n",
       "153  yes            ckd  \n",
       "157   no            ckd  \n",
       "159   no            ckd  \n",
       "171  yes            ckd  \n",
       "176  yes            ckd  \n",
       "181   no            ckd  \n",
       "189   no            ckd  \n",
       "..   ...            ...  \n",
       "368   no         notckd  \n",
       "369   no         notckd  \n",
       "370   no         notckd  \n",
       "371   no         notckd  \n",
       "372   no         notckd  \n",
       "373   no         notckd  \n",
       "374   no         notckd  \n",
       "375   no         notckd  \n",
       "376   no         notckd  \n",
       "377   no         notckd  \n",
       "379   no         notckd  \n",
       "380   no         notckd  \n",
       "382   no         notckd  \n",
       "383   no         notckd  \n",
       "384   no         notckd  \n",
       "385   no         notckd  \n",
       "386   no         notckd  \n",
       "387   no         notckd  \n",
       "388   no         notckd  \n",
       "389   no         notckd  \n",
       "390   no         notckd  \n",
       "391   no         notckd  \n",
       "392   no         notckd  \n",
       "393   no         notckd  \n",
       "394   no         notckd  \n",
       "395   no         notckd  \n",
       "396   no         notckd  \n",
       "397   no         notckd  \n",
       "398   no         notckd  \n",
       "399   no         notckd  \n",
       "\n",
       "[158 rows x 26 columns]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we assume your dataframe's variable is named `df`. If it isn't, make the appropriate changes. But do not alter the code in `scaleFeaturesDF()` just yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your (possible) code adjustment here ..\n",
    "if scaleFeatures: df = scaleFeaturesDF(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA on your dataset, reducing it to 2 principal components. Make sure your PCA model is saved in a variable called `'pca'`, and that the results of your transformation are saved in another variable `'T'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'notckd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-400d9fa30ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         X = check_array(X, dtype=[np.float64], ensure_2d=True,\n\u001b[0;32m--> 346\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'notckd'"
     ]
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(df)\n",
    "\n",
    "T = pca.transform(df)\n",
    "return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the transformed data as a scatter plot. Recall that transforming the data will result in a NumPy NDArray. You can either use MatPlotLib to graph it directly, or you can convert it back to DataFrame and have Pandas do it for you.\n",
    "\n",
    "Since we've already demonstrated how to plot directly with MatPlotLib in `Module4/assignment1.ipynb`, this time we'll show you how to convert your transformed data back into to a Pandas Dataframe and have Pandas plot it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we transformed via PCA, we no longer have column names; but we know we\n",
    "# are in `principal-component` space, so we'll just define the coordinates accordingly:\n",
    "ax = drawVectors(T, pca.components_, df.columns.values, plt, scaleFeatures)\n",
    "T  = pd.DataFrame(T)\n",
    "\n",
    "T.columns = ['component1', 'component2']\n",
    "T.plot.scatter(x='component1', y='component2', marker='o', c=labels, alpha=0.75, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
